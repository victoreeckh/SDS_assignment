{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoreeckh/SDS_assignment/blob/main/SDS_NN_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smart Distribution Systems (B-KUL-H00P3A)\n",
        "## Forecasting Competition assignment \n",
        "Wout Joris - r0786961\\\n",
        "Victor Eeckhout - r0778787"
      ],
      "metadata": {
        "id": "xaLYPz28NBnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_sU0HbMM76y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "import datetime\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, KFold\n",
        "import os\n",
        "\n",
        "#%tensorflow_version 1.x\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data reading and formatting"
      ],
      "metadata": {
        "id": "SYS23MmjVQWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "NQLVy_G_S5Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#time values of historical data\n",
        "start_date = dt.datetime(2017,1,1)\n",
        "end_date = dt.datetime(2019,12,31)"
      ],
      "metadata": {
        "id": "AE4E-XmBZQrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in Belgian day-ahead electricity prices (DAM prices)\n",
        "df_day_ahead_price = pd.read_csv(io.BytesIO(uploaded['day-ahead-price.csv']), header=0)\n",
        "df_day_ahead_price['datetime'] = pd.to_datetime(df_day_ahead_price['datetime'], utc=True)\n",
        "df_day_ahead_price['datetime'] = df_day_ahead_price['datetime'].dt.tz_localize(None)\n",
        "df_day_ahead_price.set_index('datetime', inplace=True)\n",
        "\n",
        "df_day_ahead_price.head()\n",
        "# print(df_day_ahead_price.dtypes)"
      ],
      "metadata": {
        "id": "WGFsr5qhdHar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datacleaning day ahead prices\n",
        "#empty values\n",
        "dates = pd.date_range(start=start_date, end=end_date, freq='1H')\n",
        "# print(dates[:10])\n",
        "for d in dates:\n",
        "    try:\n",
        "        p = df_day_ahead_price.loc[d]\n",
        "    except KeyError:\n",
        "        print(d)\n",
        "#no empty values found\n",
        "df_day_ahead_price =  df_day_ahead_price.fillna(method='pad')\n",
        "df_day_ahead_price = df_day_ahead_price.sort_index()\n",
        "df_day_ahead_price = df_day_ahead_price[start_date:end_date]\n",
        "\n",
        "frames = {\"DAM price\": df_day_ahead_price}"
      ],
      "metadata": {
        "id": "KTjcw24MuEO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in generation import\n",
        "df_generation_import = pd.read_csv(io.BytesIO(uploaded['generation-import.csv']), header=0, skiprows=[0,2])\n",
        "df_generation_import = df_generation_import.rename(columns = {'Unnamed: 0':'datetime'})\n",
        "df_generation_import['datetime'] = pd.to_datetime(df_generation_import['datetime'], utc=True)\n",
        "df_generation_import['datetime'] = df_generation_import['datetime'].dt.tz_localize(None)\n",
        "df_generation_import.set_index('datetime', inplace=True)\n",
        "\n",
        "# print(df_generation_import['datetime'].dtypes)\n",
        "df_generation_import.head()\n"
      ],
      "metadata": {
        "id": "B7KPaKwEKcMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datacleaning in generation import\n",
        "Load = 0; \n",
        "for col in df_generation_import.columns:\n",
        "  var_name = \"df_generation_import\" + \"_\" + col.replace(\" \", \"_\")\n",
        "  var_value = df_generation_import[col].fillna(method='pad').fillna(0)\n",
        "  var_value = var_value[start_date:end_date]\n",
        "  name_space = globals()\n",
        "  name_space[var_name] = var_value\n",
        "  frames[col] = var_value\n",
        "  Load+=var_value\n",
        "  # print(var_name)\n",
        "\n",
        "#Load is sum of generation+import\n",
        "frames['Load'] = Load\n",
        "frames['Generation'] = frames['Biomass']+frames['Fossil Gas']+frames['Fossil Oil']+frames['Hydro Pumped Storage']+\\\n",
        "                      +frames['Hydro Run-of-river and poundage']+frames['Nuclear']+frames['Other']+frames['Solar']+frames['Waste']\\\n",
        "                      +frames['Wind Offshore']+ frames['Wind Onshore']\n",
        "frames['Import'] = frames['NL'] + frames['DE_AT_LU'] + frames['FR'] + frames['GB'] + frames['DE_LU']\n",
        "frames['Wind'] = frames['Wind Offshore'] + frames['Wind Onshore']"
      ],
      "metadata": {
        "id": "3Z4Qs_6pRIvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in imbalance price\n",
        "df_imbalance_price = pd.read_csv(io.BytesIO(uploaded['imbalance-price.csv']), header=0)\n",
        "df_imbalance_price['datetime'] = pd.to_datetime(df_imbalance_price['datetime'], utc=True)\n",
        "df_imbalance_price['datetime'] = df_imbalance_price['datetime'].dt.tz_localize(None)\n",
        "df_imbalance_price.set_index('datetime', inplace=True)\n",
        "\n",
        "df_imbalance_price_long = df_imbalance_price[\"Long\"]\n",
        "df_imbalance_price_short = df_imbalance_price[\"Short\"]\n",
        "\n",
        "# print(df_imbalance_price.dtypes)\n",
        "df_imbalance_price.head()"
      ],
      "metadata": {
        "id": "wFGbi65iZZ7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datacleaning imbalance prices\n",
        "#empty values\n",
        "for d in dates:\n",
        "    try:\n",
        "        p = df_imbalance_price_long.loc[d]\n",
        "    except KeyError:\n",
        "        print(d)\n",
        "#no empty values found\n",
        "df_imbalance_price_long =  df_imbalance_price_long.fillna(method='pad')\n",
        "df_imbalance_price_long = df_imbalance_price_long.sort_index()\n",
        "df_imbalance_price_long = df_imbalance_price_long[start_date:end_date]\n",
        "frames[\"imbalance price long\"] = df_imbalance_price_long\n",
        "\n",
        "for d in dates:\n",
        "    try:\n",
        "        p = df_imbalance_price_short.loc[d]\n",
        "    except KeyError:\n",
        "        print(d)\n",
        "#no empty values found\n",
        "df_imbalance_price_short =  df_imbalance_price_short.fillna(method='pad')\n",
        "df_imbalance_price_short = df_imbalance_price_short.sort_index()\n",
        "df_imbalance_price_short = df_imbalance_price_short[start_date:end_date]\n",
        "frames[\"imbalance price short\"] = df_imbalance_price_short"
      ],
      "metadata": {
        "id": "69wZm-pma-_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read in solar values\n",
        "df_solar_and_wind_forecast = pd.read_csv(io.BytesIO(uploaded['wind-and-solar.csv']), header=0)\n",
        "df_solar_and_wind_forecast['datetime'] = pd.to_datetime(df_solar_and_wind_forecast['datetime'], utc=True)\n",
        "df_solar_and_wind_forecast['datetime'] = df_solar_and_wind_forecast['datetime'].dt.tz_localize(None)\n",
        "df_solar_and_wind_forecast.set_index('datetime', inplace=True)\n",
        "\n",
        "df_solar_forecast = df_solar_and_wind_forecast['Solar']\n",
        "df_wind_offshore_forecast = df_solar_and_wind_forecast['Wind Offshore']\n",
        "df_wind_onshore_forecast = df_solar_and_wind_forecast['Wind Onshore']\n",
        "\n",
        "df_solar_and_wind_forecast.head()\n",
        "# df_solar.head()\n",
        "# df_wind_onshore.head()"
      ],
      "metadata": {
        "id": "JzFX5zDtVWyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datacleaning wind and solar\n",
        "df_solar_forecast =  df_solar_forecast.fillna(method='pad')\n",
        "df_solar_forecast = df_solar_forecast[start_date:end_date]\n",
        "frames[\"solar forecast\"] = df_solar_forecast\n",
        "df_wind_offshore_forecast =  df_wind_offshore_forecast.fillna(method='pad')\n",
        "df_wind_offshore_forecast = df_wind_offshore_forecast[start_date:end_date]\n",
        "frames[\"wind offshore forecast\"] = df_wind_offshore_forecast\n",
        "df_wind_onshore_forecast =  df_wind_onshore_forecast.fillna(method='pad')\n",
        "df_wind_onshore_forecast = df_wind_onshore_forecast[start_date:end_date]\n",
        "frames[\"wind onshore forecast\"] = df_wind_onshore_forecast\n",
        "frames[\"wind forecast\"] = df_wind_onshore_forecast + df_wind_offshore_forecast"
      ],
      "metadata": {
        "id": "-1yAeG5wvDe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing granularities\n",
        "d = {}\n",
        "for key,frame in frames.items():\n",
        "  # print(type(frame))\n",
        "  frames[key] = frame.resample('15T').pad()\n",
        "  d[key] = frames[key].values\n",
        "  # print(frame)\n",
        "  # print(len(frame))\n",
        "d[\"DAM price\"] = d[\"DAM price\"].flatten()\n"
      ],
      "metadata": {
        "id": "8Nn6yz4UwWTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating one dataframe\n",
        "\n",
        "data = pd.DataFrame(index=frames[\"DAM price\"].index, data=d)\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "ONbbyXIpsj9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing outliers\n",
        "#(only for prices)\n",
        "\n",
        "# print(frames.keys())\n",
        "\n",
        "for key in {\"DAM price\", \"imbalance price long\", \"imbalance price short\"}:\n",
        "  frame = data[key]\n",
        "  mean = frame.mean()\n",
        "  # print(mean)\n",
        "  std = frame.std()\n",
        "  # print(std)\n",
        "  if key == \"DAM price\":\n",
        "    n_std = 5\n",
        "  else:\n",
        "    n_std = 10\n",
        "\n",
        "  data[key][(frame >= mean + n_std*std)] = mean + n_std*std \n",
        "  data[key][(frame <= mean - n_std*std)] = mean + n_std*std \n",
        "\n",
        "#accuracy function\n",
        "def get_accuracy(x, y):\n",
        "    return np.mean(np.abs(x - y))/np.mean(x)\n"
      ],
      "metadata": {
        "id": "gDDcFu_L01GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some figures\n",
        "plt.figure()\n",
        "plt.subplot(311)\n",
        "plt.plot(data[\"DAM price\"], label=\"DAM price\")\n",
        "plt.legend(frameon=False)\n",
        "plt.subplot(312)\n",
        "plt.plot(data[\"imbalance price long\"], label=\"imbalance price long\")\n",
        "plt.legend(frameon=False)\n",
        "plt.subplot(313)\n",
        "plt.plot(data[\"imbalance price short\"], label=\"imbalance price short\")\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2K9cQQLU5X6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Dataset"
      ],
      "metadata": {
        "id": "0jP8t9247Z-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autocorrelation\n",
        "Biggest correlation with previous day, followed by the day before and the same day in the previous week is also substantially autocorrelated. We will use these features to construct the training data."
      ],
      "metadata": {
        "id": "4NpWMnIoSsw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Autocorellation\n",
        "lags = np.arange(1, 96*10)\n",
        "acors = []\n",
        "for lag in lags:\n",
        "    acors.append(data['DAM price'].autocorr(lag))\n",
        "plt.figure()\n",
        "plt.plot(lags/4/24.0, acors)\n",
        "plt.xlabel('Time lag in days')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "jGdxQB7s7gcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hours = 24\n",
        "#one day ahead\n",
        "start_X_1_d_ahead = datetime.datetime(2017, 1, 7, 0, 0)\n",
        "end_X_1_d_ahead = datetime.datetime(2018, 12, 29, 23, 45)\n",
        "X_1_d_ahead = data['DAM price'][start_X_1_d_ahead:end_X_1_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#two days ahead\n",
        "start_X_2_d_ahead = datetime.datetime(2017, 1, 6, 0, 0)\n",
        "end_X_2_d_ahead = datetime.datetime(2018, 12, 28, 23, 45)\n",
        "X_2_d_ahead = data['DAM price'][start_X_2_d_ahead:end_X_2_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#a week ahead\n",
        "start_X_7_d_ahead = datetime.datetime(2017, 1, 1, 0, 0)\n",
        "end_X_7_d_ahead = datetime.datetime(2018, 12, 23, 23, 45)\n",
        "X_7_d_ahead = data['DAM price'][start_X_7_d_ahead:end_X_7_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "start_Y = datetime.datetime(2017, 1, 8, 0, 0)\n",
        "end_Y = datetime.datetime(2018, 12, 30, 23, 45)\n",
        "\n",
        "Y = data['DAM price'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "# solar load data and forecast\n",
        "S_load = data['Solar'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "S_forecast = data['solar forecast'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "# wind (off- + onshore) load data and forecast\n",
        "W_load = data['Wind'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "W_forecast = data['wind forecast'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Total load\n",
        "L = data['Load'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Imbalance price long\n",
        "I_long = data['imbalance price long'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Imbalance price short\n",
        "I_short = data['imbalance price short'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Import\n",
        "Im = data['Import'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Generation\n",
        "G = data['Generation'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "##Construct training matrix\n",
        "rows = X_1_d_ahead.shape[0]\n",
        "col = X_1_d_ahead.shape[1]\n",
        "\n",
        "#CHANGE FEATURES HERE\n",
        "use_X_1_d_ahead = 1\n",
        "use_X_2_d_ahead = 0\n",
        "use_X_7_d_ahead = 1\n",
        "use_S_forecast = 1\n",
        "use_W_forecast = 0\n",
        "use_S_Load = 0\n",
        "use_W_Load = 0\n",
        "use_L = 0\n",
        "use_I_long = 1\n",
        "use_I_short = 1\n",
        "use_Import = 0\n",
        "use_G = 0\n",
        "\n",
        "n = use_X_1_d_ahead + use_X_2_d_ahead + use_X_7_d_ahead + use_S_forecast\\\n",
        "    + use_W_forecast + use_S_Load + use_W_Load + use_L+use_I_long+use_I_short\\\n",
        "    +use_Import + use_G\n",
        "T = np.zeros((rows,n*col))\n",
        "\n",
        "for i in range(0,rows):\n",
        "  j = 0\n",
        "  while j!=n:\n",
        "    if use_X_1_d_ahead:\n",
        "      T[i,j*col:(j+1)*col] = X_1_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_X_2_d_ahead:\n",
        "      T[i,j*col:(j+1)*col] = X_2_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_X_7_d_ahead:\n",
        "      T[i,j*col:(j+1)*col] = X_7_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_S_forecast:\n",
        "      T[i,j*col:(j+1)*col] = S_forecast[i,0:col]\n",
        "      j+=1\n",
        "    if use_W_forecast:\n",
        "      T[i,j*col:(j+1)*col] = W_forecast[i,0:col]\n",
        "      j+=1\n",
        "    if use_S_Load:\n",
        "      T[i,j*col:(j+1)*col] = S_load[i,0:col]\n",
        "      j+=1\n",
        "    if use_W_Load:\n",
        "      T[i,j*col:(j+1)*col] = W_load[i,0:col]\n",
        "      j+=1\n",
        "    if use_L:\n",
        "      T[i,j*col:(j+1)*col] = L[i,0:col]\n",
        "      j+=1\n",
        "    if use_I_long:\n",
        "      T[i,j*col:(j+1)*col] = I_long[i,0:col]\n",
        "      j+=1\n",
        "    if use_I_short:\n",
        "      T[i,j*col:(j+1)*col] = I_short[i,0:col]\n",
        "      j+=1\n",
        "    if use_Import:\n",
        "      T[i,j*col:(j+1)*col] = Im[i,0:col]\n",
        "      j+=1\n",
        "    if use_G:\n",
        "      T[i,j*col:(j+1)*col] = G[i,0:col]\n",
        "      j+=1\n",
        "\n",
        "\n",
        "# for i in range(0,rows):\n",
        "#     T[i,0:col] = X_1_d_ahead[i,0:col]\n",
        "#     T[i,col:2*col] = X_2_d_ahead[i,0:col]\n",
        "#     T[i,2*col:3*col] = X_7_d_ahead[i,0:col]\n",
        "#     T[i,3*col:4*col] = S_forecast[i,0:col]\n",
        "#     T[i,4*col:5*col] = W_forecast[i,0:col]\n",
        "#     T[i,5*col:6*col] = L[i,0:col]\n",
        "print('shape of T ' + str(T.shape))\n",
        "Neurons_l_1 = T.shape[1]"
      ],
      "metadata": {
        "id": "zfkh842yBcES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation dataset"
      ],
      "metadata": {
        "id": "4I1Vgt7_0caW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_hours = 24\n",
        "#one day ahead\n",
        "start_X_1_d_ahead = datetime.datetime(2019, 1, 7, 0, 0)\n",
        "end_X_1_d_ahead = datetime.datetime(2019, 12, 29, 23, 45)\n",
        "X_1_d_ahead = data['DAM price'][start_X_1_d_ahead:end_X_1_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#two days ahead\n",
        "start_X_2_d_ahead = datetime.datetime(2019, 1, 6, 0, 0)\n",
        "end_X_2_d_ahead = datetime.datetime(2019, 12, 28, 23, 45)\n",
        "X_2_d_ahead = data['DAM price'][start_X_2_d_ahead:end_X_2_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#a week ahead\n",
        "start_X_7_d_ahead = datetime.datetime(2019, 1, 1, 0, 0)\n",
        "end_X_7_d_ahead = datetime.datetime(2019, 12, 23, 23, 45)\n",
        "X_7_d_ahead = data['DAM price'][start_X_7_d_ahead:end_X_7_d_ahead].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "start_Y = datetime.datetime(2019, 1, 8, 0, 0)\n",
        "end_Y = datetime.datetime(2019, 12, 30, 23, 45)\n",
        "\n",
        "Y_val = data['DAM price'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "# solar load data and forecast\n",
        "S_load = data['Solar'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "S_forecast = data['solar forecast'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "# wind (off- + onshore) load data and forecast\n",
        "W_load = data['Wind'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "W_forecast = data['wind forecast'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "#Total load\n",
        "L = data['Load'][start_Y:end_Y].resample('1H').mean().values.reshape(-1, n_hours)\n",
        "\n",
        "##Construct training matrix\n",
        "rows = X_1_d_ahead.shape[0]\n",
        "col = X_1_d_ahead.shape[1]\n",
        "\n",
        "T_val = np.zeros((rows,n*col))\n",
        "\n",
        "for i in range(0,rows):\n",
        "  j = 0\n",
        "  while j!=n:\n",
        "    if use_X_1_d_ahead:\n",
        "      T_val[i,j*col:(j+1)*col] = X_1_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_X_2_d_ahead:\n",
        "      T_val[i,j*col:(j+1)*col] = X_2_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_X_7_d_ahead:\n",
        "      T_val[i,j*col:(j+1)*col] = X_7_d_ahead[i,0:col]\n",
        "      j+=1\n",
        "    if use_S_forecast:\n",
        "      T_val[i,j*col:(j+1)*col] = S_forecast[i,0:col]\n",
        "      j+=1\n",
        "    if use_W_forecast:\n",
        "      T_val[i,j*col:(j+1)*col] = W_forecast[i,0:col]\n",
        "      j+=1\n",
        "    if use_S_Load:\n",
        "      T_val[i,j*col:(j+1)*col] = S_load[i,0:col]\n",
        "      j+=1\n",
        "    if use_W_Load:\n",
        "      T_val[i,j*col:(j+1)*col] = W_load[i,0:col]\n",
        "      j+=1\n",
        "    if use_L:\n",
        "      T_val[i,j*col:(j+1)*col] = L[i,0:col]\n",
        "      j+=1\n",
        "    if use_I_long:\n",
        "      T[i,j*col:(j+1)*col] = I_long[i,0:col]\n",
        "      j+=1\n",
        "    if use_I_short:\n",
        "      T[i,j*col:(j+1)*col] = I_short[i,0:col]\n",
        "      j+=1\n",
        "    if use_Import:\n",
        "      T[i,j*col:(j+1)*col] = Im[i,0:col]\n",
        "      j+=1\n",
        "    if use_G:\n",
        "      T[i,j*col:(j+1)*col] = G[i,0:col]\n",
        "      j+=1\n",
        "\n",
        "\n",
        "# for i in range(0,rows):\n",
        "#     T_val[i,0:col] = X_1_d_ahead[i,0:col]\n",
        "#     T_val[i,col:2*col] = X_2_d_ahead[i,0:col]\n",
        "#     T_val[i,2*col:3*col] = X_7_d_ahead[i,0:col]\n",
        "#     T_val[i,3*col:4*col] = S_forecast[i,0:col]\n",
        "#     T_val[i,4*col:5*col] = W_forecast[i,0:col]\n",
        "#     T_val[i,5*col:6*col] = L[i,0:col]\n",
        "print('shape of T_val ' + str(T_val.shape))"
      ],
      "metadata": {
        "id": "RGgBowKsFocQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training NN"
      ],
      "metadata": {
        "id": "z6RnWEyp2Try"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neurons = [Neurons_l_1,120,24]\n",
        "activation_functions = ['relu','relu','linear']\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons[0], input_dim=T.shape[1], activation=activation_functions[0]))\n",
        "model.add(Dense(neurons[1], activation=activation_functions[1]))\n",
        "model.add(Dense(neurons[2], activation=activation_functions[2]))\n",
        "\n",
        "rprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-6)\n",
        "model.compile(loss='mean_squared_error', optimizer=rprop)\n",
        "\n",
        "output_training = model.fit(T, Y, epochs=700, batch_size=32, verbose=0, validation_data=(T_val,Y_val))\n",
        "mse = output_training.history['loss'][-1]\n",
        "print('- mse is %.4f' % mse + ' @ ' + str(len(output_training.history['loss'])))"
      ],
      "metadata": {
        "id": "UBL9hdf82S_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early stopping"
      ],
      "metadata": {
        "id": "y-7XkUMK4EIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights\n",
        "ww = model.get_weights()\n",
        "\n",
        "#Running mean function\n",
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "mean_window= 20\n",
        "plt.figure()\n",
        "train_loss = plt.plot(running_mean(x=output_training.history['loss'], N=mean_window), label='training error')\n",
        "val_loss = plt.plot(running_mean(x=output_training.history['val_loss'], N=mean_window), color='red', label='validation error')\n",
        "plt.xlim([0, 500])\n",
        "plt.ylim([0, 500])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BaVPLKj34Jda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "huG5Tn2DJRj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#on the basis of training set\n",
        "predict_nn = model.predict(T)\n",
        "\n",
        "print(get_accuracy(Y.flatten(), predict_nn.flatten()))\n",
        "\n",
        "# Plots\n",
        "plt.figure()\n",
        "plt.plot(Y[:10,:].flatten(), color='blue', label='actual price')\n",
        "plt.plot(predict_nn[:10,:].flatten(), color='red', label='forecast NN')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IT7HKb56JUCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#on the basis of validation set\n",
        "\n",
        "Y_pred = model.predict(T_val)\n",
        "print('input_features ' + str(Y_val.shape))\n",
        "\n",
        "def mean_squared_error(y1, y2):\n",
        "    return np.mean(np.power(y1-y2, 2), axis=0)\n",
        "\n",
        "mse = mean_squared_error(np.reshape(Y_val, (8568, 1)), np.reshape(Y_pred, (8568, 1)))\n",
        "print(mse)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Y_val[:10,:].flatten(), color='blue', label='actual price')\n",
        "plt.plot(Y_pred[:10,:].flatten(), color='red', label='forecast NN')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jhyTuKaiKWHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GSOfXgDoLtFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in week 1"
      ],
      "metadata": {
        "id": "b5BMXxojJ25U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## First week\n",
        "\n",
        "#input price data\n",
        "#granularity already in hours\n",
        "\n",
        "# df_day_ahead_price = pd.read_csv(io.BytesIO(uploaded['day-ahead-price_week1.csv']), header=0)\n",
        "# df_day_ahead_price.head()\n",
        "df_day_ahead_price = np.array(pd.read_csv('day-ahead-price_week1.csv', header=0))\n",
        "# print(len(df_day_ahead_price))\n",
        "# print(df_day_ahead_price)"
      ],
      "metadata": {
        "id": "h0qDyRY1J6NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input forecasted solar and wind\n",
        "# granularity already in hours\n",
        "df_solar_and_wind_forecast = pd.read_csv(io.BytesIO(uploaded['wind-and-solar_week1.csv']), header=0)\n",
        "df_solar_and_wind_forecast.head()\n",
        "df_solar_forecast = df_solar_and_wind_forecast['Solar']\n",
        "df_wind_forecast = df_solar_and_wind_forecast['Wind Offshore'] + df_solar_and_wind_forecast['Wind Onshore']\n",
        "# df_solar_forecast.head()\n",
        "# df_wind_forecast.head()\n"
      ],
      "metadata": {
        "id": "UMJqYLafUNlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input Imbalance prices\n",
        "#granularity still 15'\n",
        "df_imbalance_price = pd.read_csv(io.BytesIO(uploaded['imbalance-price_week1.csv']), header=0)\n",
        "df_imbalance_price_long = df_imbalance_price['Long']\n",
        "df_imbalance_price_short = df_imbalance_price['Short']\n",
        "# df_imbalance_price.head()\n",
        "# df_imbalance_price_long.head()\n",
        "# df_imbalance_price_short.head()\n",
        "\n",
        "# 15' --> 1h\n",
        "# by interpolation\n",
        "i = int(len(df_imbalance_price_long)/4)\n",
        "imbalance_long = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_long[r] = (df_imbalance_price_long[r*4]+df_imbalance_price_long[r*4+1]+df_imbalance_price_long[r*4+2]+df_imbalance_price_long[r*4+3])/4\n",
        "print(imbalance_long.shape)\n",
        "\n",
        "imbalance_short = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_short[r] = (df_imbalance_price_short[r*4]+df_imbalance_price_short[r*4+1]+df_imbalance_price_short[r*4+2]+df_imbalance_price_short[r*4+3])/4\n",
        "print(imbalance_short.shape)"
      ],
      "metadata": {
        "id": "dpJW0Ob_YpKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine code in a matrix\n",
        "#Depends on chosen features\n",
        "\n",
        "D = np.zeros((1,120))\n",
        "p = len(df_solar_forecast) #7d of data available\n",
        "q = len(df_day_ahead_price) #only 6d of data available\n",
        "\n",
        "D[0,0:24] = df_day_ahead_price[q-24:q,0]\n",
        "D[0,24:2*24] = df_day_ahead_price[0:24,0]\n",
        "D[0,2*24:3*24] = df_solar_forecast[p-24:p]\n",
        "D[0,3*24:4*24] = imbalance_long[p-24:p]\n",
        "D[0,4*24:5*24] = imbalance_short[p-24:p]\n",
        "\n",
        "A1 = model.predict(D)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(A1.flatten(), color='red', label='forecast NN')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IxfP6NxEeGWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in week 2"
      ],
      "metadata": {
        "id": "G21S5u1wB5a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Second week\n",
        "\n",
        "#input price data\n",
        "#granularity already in hours\n",
        "\n",
        "# df_day_ahead_price = pd.read_csv(io.BytesIO(uploaded['day-ahead-price_week2.csv']), header=0)\n",
        "# df_day_ahead_price.head()\n",
        "df_day_ahead_price2 = np.array(pd.read_csv('day-ahead-price_week2.csv', header=0))\n",
        "# print(len(df_day_ahead_price))\n",
        "# print(df_day_ahead_price)"
      ],
      "metadata": {
        "id": "npn6XIAOB2Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input forecasted solar and wind\n",
        "# granularity already in hours\n",
        "df_solar_and_wind_forecast2 = pd.read_csv(io.BytesIO(uploaded['wind-and-solar_week2.csv']), header=0)\n",
        "df_solar_and_wind_forecast2.head()\n",
        "df_solar_forecast2 = df_solar_and_wind_forecast2['Solar']\n",
        "df_wind_forecast2 = df_solar_and_wind_forecast2['Wind Offshore'] + df_solar_and_wind_forecast2['Wind Onshore']\n",
        "# df_solar_forecast.head()\n",
        "# df_wind_forecast.head()"
      ],
      "metadata": {
        "id": "wLE-EvENCU_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input Imbalance prices\n",
        "#granularity still 15'\n",
        "df_imbalance_price2 = pd.read_csv(io.BytesIO(uploaded['imbalance-price_week2.csv']), header=0)\n",
        "df_imbalance_price_long2 = df_imbalance_price2['Long']\n",
        "df_imbalance_price_short2 = df_imbalance_price2['Short']\n",
        "# df_imbalance_price.head()\n",
        "# df_imbalance_price_long.head()\n",
        "# df_imbalance_price_short.head()\n",
        "\n",
        "# 15' --> 1h\n",
        "# by interpolation\n",
        "i = int(len(df_imbalance_price_long2)/4)\n",
        "imbalance_long2 = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_long2[r] = (df_imbalance_price_long2[r*4]+df_imbalance_price_long2[r*4+1]+df_imbalance_price_long2[r*4+2]+df_imbalance_price_long2[r*4+3])/4\n",
        "print(imbalance_long2.shape)\n",
        "\n",
        "imbalance_short2 = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_short2[r] = (df_imbalance_price_short2[r*4]+df_imbalance_price_short2[r*4+1]+df_imbalance_price_short2[r*4+2]+df_imbalance_price_short2[r*4+3])/4\n",
        "print(imbalance_short2.shape)"
      ],
      "metadata": {
        "id": "ivTCh0HcCcgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine code in a matrix\n",
        "#Depends on chosen features\n",
        "\n",
        "D = np.zeros((1,120))\n",
        "p = len(df_solar_forecast) #7d of data available\n",
        "q = len(df_day_ahead_price) #only 6d of data available\n",
        "\n",
        "D[0,0:24] = df_day_ahead_price2[q-24:q,0]\n",
        "D[0,24:2*24] = df_day_ahead_price2[0:24,0]\n",
        "D[0,2*24:3*24] = df_solar_forecast2[p-24:p]\n",
        "D[0,3*24:4*24] = imbalance_long2[p-24:p]\n",
        "D[0,4*24:5*24] = imbalance_short2[p-24:p]\n",
        "\n",
        "A2 = model.predict(D)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(A2.flatten(), color='red', label='forecast NN')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6Ansb7bCmAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in week 3"
      ],
      "metadata": {
        "id": "Xs6FgNIoJ_7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Third week\n",
        "\n",
        "#input price data\n",
        "#granularity already in hours\n",
        "\n",
        "# df_day_ahead_price = pd.read_csv(io.BytesIO(uploaded['day-ahead-price_week3.csv']), header=0)\n",
        "# df_day_ahead_price.head()\n",
        "df_day_ahead_price3 = np.array(pd.read_csv('day-ahead-price_week3.csv', header=0))\n",
        "# print(len(df_day_ahead_price))\n",
        "# print(df_day_ahead_price)"
      ],
      "metadata": {
        "id": "GQlMMP4WJ-cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input forecasted solar and wind\n",
        "# granularity already in hours\n",
        "df_solar_and_wind_forecast3 = pd.read_csv(io.BytesIO(uploaded['wind-and-solar_week3.csv']), header=0)\n",
        "df_solar_and_wind_forecast3.head()\n",
        "df_solar_forecast3 = df_solar_and_wind_forecast3['Solar']\n",
        "df_wind_forecast3 = df_solar_and_wind_forecast3['Wind Offshore'] + df_solar_and_wind_forecast3['Wind Onshore']\n",
        "# df_solar_forecast.head()\n",
        "# df_wind_forecast.head()"
      ],
      "metadata": {
        "id": "jK2ZPe5LKLa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input Imbalance prices\n",
        "#granularity still 15'\n",
        "df_imbalance_price3 = pd.read_csv(io.BytesIO(uploaded['imbalance-price_week3.csv']), header=0)\n",
        "df_imbalance_price_long3 = df_imbalance_price3['Long']\n",
        "df_imbalance_price_short3 = df_imbalance_price3['Short']\n",
        "# df_imbalance_price.head()\n",
        "# df_imbalance_price_long.head()\n",
        "# df_imbalance_price_short.head()\n",
        "\n",
        "# 15' --> 1h\n",
        "# by interpolation\n",
        "i = int(len(df_imbalance_price_long3)/4)\n",
        "imbalance_long3 = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_long3[r] = (df_imbalance_price_long3[r*4]+df_imbalance_price_long3[r*4+1]+df_imbalance_price_long3[r*4+2]+df_imbalance_price_long3[r*4+3])/4\n",
        "print(imbalance_long3.shape)\n",
        "\n",
        "imbalance_short3 = np.zeros((i))\n",
        "\n",
        "for r in range(0,i-1):\n",
        "   imbalance_short3[r] = (df_imbalance_price_short3[r*4]+df_imbalance_price_short3[r*4+1]+df_imbalance_price_short3[r*4+2]+df_imbalance_price_short3[r*4+3])/4\n",
        "print(imbalance_short3.shape)"
      ],
      "metadata": {
        "id": "FMmBD--oKVZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine code in a matrix\n",
        "#Depends on chosen features\n",
        "\n",
        "D = np.zeros((1,120))\n",
        "p = len(df_solar_forecast) #7d of data available\n",
        "q = len(df_day_ahead_price) #only 6d of data available\n",
        "\n",
        "D[0,0:24] = df_day_ahead_price3[q-24:q,0]\n",
        "D[0,24:2*24] = df_day_ahead_price3[0:24,0]\n",
        "D[0,2*24:3*24] = df_solar_forecast3[p-24:p]\n",
        "D[0,3*24:4*24] = imbalance_long3[p-24:p]\n",
        "D[0,4*24:5*24] = imbalance_short3[p-24:p]\n",
        "\n",
        "A3 = model.predict(D)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(A3.flatten(), color='red', label='forecast NN')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2zAiQ7URKq97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting predictions in file"
      ],
      "metadata": {
        "id": "s93-1qMoK29h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.zeros((72))\n",
        "\n",
        "P[0:24] = A1\n",
        "P[24:48] = A2\n",
        "P[48:72] = A3\n",
        "\n",
        "P = np.transpose(P)\n",
        "P_data = DataFrame(P)\n",
        "\n",
        "P_data.to_csv('predictions.csv', header=False)\n",
        "# P_data.head(72)"
      ],
      "metadata": {
        "id": "fHBkzgiTLCIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}